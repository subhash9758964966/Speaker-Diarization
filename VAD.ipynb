{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPGdx5LQ70t9ZOwxSK28Ol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muskang48/Speaker-Diarization/blob/master/VAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIQeYWzhImTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install webrtcvad\n",
        "import contextlib\n",
        "import numpy as np\n",
        "import wave\n",
        "import librosa\n",
        "import webrtcvad\n",
        "\n",
        "\n",
        "def read_wave(path):\n",
        "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "        num_channels = wf.getnchannels()\n",
        "        assert num_channels == 1\n",
        "        sample_width = wf.getsampwidth()\n",
        "        assert sample_width == 2\n",
        "        sample_rate = wf.getframerate()\n",
        "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "        pcm_data = wf.readframes(wf.getnframes())\n",
        "        return pcm_data, sample_rate\n",
        "\n",
        "\n",
        "class Frame(object):\n",
        "  def __init__(self, bytes, timestamp, duration):\n",
        "        self.bytes = bytes\n",
        "        self.timestamp = timestamp\n",
        "        self.duration = duration\n",
        "\n",
        "\n",
        "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "    offset = 0\n",
        "    timestamp = 0.0\n",
        "    duration = (float(n) / sample_rate) / 2.0\n",
        "    while offset + n < len(audio):\n",
        "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "        timestamp += duration\n",
        "        offset += n\n",
        "\n",
        "\n",
        "def vad_collector(vad, frames, sample_rate):\n",
        "    is_speech = []\n",
        "    for frame in frames:\n",
        "        is_speech.append(vad.is_speech(frame.bytes, sample_rate))\n",
        "    return is_speech\n",
        "\n",
        "\n",
        "def vad(file):\n",
        "    audio, sample_rate = read_wave(file)\n",
        "    vad = webrtcvad.Vad(2)\n",
        "    frames = frame_generator(10, audio, sample_rate)\n",
        "    frames = list(frames)\n",
        "    segments = vad_collector(vad, frames, sample_rate)\n",
        "    return segments\n",
        "\n",
        "def speech(file):\n",
        "  dummy = 0\n",
        "  data = []\n",
        "  segments = vad(file)\n",
        "  audio, sr = librosa.load(file)\n",
        "  for i in segments:\n",
        "    if i == True:\n",
        "      data.append(audio[dummy:dummy + 480])\n",
        "      dummy = dummy + 480\n",
        "    else:\n",
        "      dummy = dummy + 480\n",
        "  data = np.ravel(np.asarray(data))\n",
        "\n",
        "  return data\n",
        "\n",
        "def fxn(file):\n",
        "  segments = vad(file)\n",
        "  segments = np.asarray(segments)\n",
        "  dummy = 0.01*np.where(segments[:-1] != segments[1:])[0] +.01 \n",
        "  dummy = np.delete(dummy, len(dummy)-1)\n",
        "\n",
        "  if len(dummy)%2==0:\n",
        "    dummy = dummy\n",
        "  else:\n",
        "    dummy = np.delete(dummy, len(dummy)-1)\n",
        "  \n",
        "  voice = dummy.reshape(int(len(dummy)/2),2)\n",
        "  return voice"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
